---
title: "Exercide 4"
author: "Adityo Das Gupta"
date: "03/04/2023"
output:
  html_document:
    df_print: paged
---

```{r,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(arrow)
library(readr)
library(gender)
library(wru)
library(lubridate)
library(ggplot2)
library(igraph)
library(ggraph)
library(tidygraph)
```

### 1. Load data, get gender, and create `app_proc_time` column

### Load data
```{r}
data_path <- "/Users/adityodasgupta/Documents/McGill/ORGB/672_project_data/"
applications <- read_parquet(paste0(data_path,"app_data_sample.parquet"))
edges <- read_csv(paste0(data_path,"edges_sample.csv"))

applications
edges
```




## Get gender for examiners


```{r gender-1}
#install_genderdata_package() # only run this line the first time you use the package, to get data for it
# get a list of first names without repetitions
examiner_names <- applications %>% 
  distinct(examiner_name_first)
#Now let's use function `gender()` as shown in the example for the package to attach a gender and probability to each name and put the results into the table `examiner_names_gender`
# get a table of names and gender
examiner_names_gender <- examiner_names %>% 
  do(results = gender(.$examiner_name_first, method = "ssa")) %>% 
  unnest(cols = c(results), keep_empty = TRUE) %>% 
  select(
    examiner_name_first = name,
    gender,
    proportion_female
  )
examiner_names_gender
# Finally, let's join that table back to our original applications data and discard the temporary tables we have just created to reduce clutter in our environment.
# remove extra columns from the gender table
examiner_names_gender <- examiner_names_gender %>% 
  select(examiner_name_first, gender)
# joining gender back to the dataset
applications <- applications %>% 
  left_join(examiner_names_gender, by = "examiner_name_first")
# cleaning up
rm(examiner_names)
rm(examiner_names_gender)
gc()
```

## Guess the examiner's race



```{r}
examiner_surnames <- applications %>% 
  select(surname = examiner_name_last) %>% 
  distinct()
examiner_surnames
```

```{r race-1}
examiner_race <- predict_race(voter.file = examiner_surnames, surname.only = T) %>% 
  as_tibble()
examiner_race
```


```{r}
examiner_race <- examiner_race %>% 
  mutate(max_race_p = pmax(pred.asi, pred.bla, pred.his, pred.oth, pred.whi)) %>% 
  mutate(race = case_when(
    max_race_p == pred.asi ~ "Asian",
    max_race_p == pred.bla ~ "black",
    max_race_p == pred.his ~ "Hispanic",
    max_race_p == pred.oth ~ "other",
    max_race_p == pred.whi ~ "white",
    TRUE ~ NA_character_
  ))
examiner_race
# Let's join the data back to the applications table.
# removing extra columns
examiner_race <- examiner_race %>% 
  select(surname,race)
applications <- applications %>% 
  left_join(examiner_race, by = c("examiner_name_last" = "surname"))
rm(examiner_race)
rm(examiner_surnames)
gc()
```

## Examiner's tenure 



```{r tenure-1}
examiner_dates <- applications %>% 
  select(examiner_id, filing_date, appl_status_date) 
examiner_dates

examiner_dates <- examiner_dates %>% 
  mutate(start_date = ymd(filing_date), end_date = as_date(dmy_hms(appl_status_date)))


examiner_dates <- examiner_dates %>% 
  group_by(examiner_id) %>% 
  summarise(
    earliest_date = min(start_date, na.rm = TRUE), 
    latest_date = max(end_date, na.rm = TRUE),
    tenure_days = interval(earliest_date, latest_date) %/% days(1)
    ) %>% 
  filter(year(latest_date)<2018)
examiner_dates
# Joining back to the applications data.
applications <- applications %>% 
  left_join(examiner_dates, by = "examiner_id")
rm(examiner_dates)
gc()
```
## Application Processing Time


## Clean Data

```{r cleaning the data}
# Remove Nas from status date and gender
applications <- applications %>% 
  filter(!is.na(appl_status_date) | !is.na(gender) | !is.na(race))
# Clean Date format
#get the date format cleaned
applications$Date_time=as.Date(applications$appl_status_date, format="%d%b%Y")
#get the date format for the filing date cleaned
applications$filing_date=as.Date(applications$filing_date, format="%d%b%Y")
```

## Pre-process



```{r pre-process data 1}
#Remove all the data we will not need based on application status
exclude_list=c("PEND")
applications <- applications %>%
  filter(!disposal_type %in% exclude_list)
```



```{r data type conversion}
#Setting Gender as factor
applications$gender = as.factor(applications$gender)
#Setting ethnicity as factor
applications$race = as.factor(applications$race)
#Setting disposal type as factor
applications$disposal_type = as.factor(applications$disposal_type)
#setting the technology center as a factor
applications$tc = as.factor(applications$tc)
```

# 1. Create 'app_proc_time' 

```{r feature engineering}
#this is the amount of time in days that the applications take
applications$app_proc_time <- applications$Date_time - applications$filing_date
applications$app_proc_time <- as.numeric(applications$app_proc_time)

```








##Nodes & Edges Creation
First we need to create the netwrok data to calculate centrality
We will remove any records that contain NAs to avoid future issues with coding

```{r}
#Create the edges from edge data
edges_backup=edges
#edges=edges_backup
edges <- edges %>%
  mutate(from=ego_examiner_id,to=alter_examiner_id) %>%
  select(from, to) %>%
  drop_na()
#Create Nodes from Edges Data
nodes <-as.data.frame(do.call(rbind,append(as.list(edges$from),as.list(edges$to))))
nodes <- nodes %>%
  mutate(id=V1) %>%
  select(id) %>%
  distinct(id) %>%
  drop_na()
```


## Closeness Measures

We will now add 3 closeness measures to the nodes data frame:

1.Degree Centrality: The number of connections (or edges) that each node has.
2. Closness Centrality : A measure that calculates the ability to spread information efficiently via the edges the node is connected to. It is calculated as the inverse of the average shortest path between nodes.
3: Betweenness Centrality: A measure that detects a nodeâ€™s influence over the flow of information within a graph.

```{r degree central igraph,echo=FALSE}
library(igraph)
library(tidygraph)
library(tidyverse)
```

```{r}
g <- igraph::graph_from_data_frame(edges, vertices = nodes) %>% as_tbl_graph(directed=TRUE)
#not sure why this isnt working
#g = tbl_graph(nodes = nodes, edges = edges, directed = FALSE)
g <- g %>% 
  activate(nodes) %>% 
  mutate(degree_cen = centrality_degree(),
         closeness_cen = centrality_closeness(),
         betweenness_cen = centrality_betweenness()) %>% 
  activate(edges)
tg_nodes <-
  g %>%
  activate(nodes) %>%
  data.frame() %>%
  mutate(name=as.integer(name))
nodes <- nodes %>%
  left_join(tg_nodes,by=c("id"="name")) 
remove(g,tg_nodes)
```

Time to visualise the degree centralities and numeric data

```{r}
final_data <- applications %>%
  left_join(nodes,by=c("examiner_id"="id"))

net <- igraph::graph_from_data_frame(edges, vertices = nodes) %>% as_tbl_graph(directed=TRUE)
plot(net, edge.arrow.size=.4,vertex.label=NA,vertex.size=4,vertex.color="blue", 
     edge.color="green")
```



```{r regression gender}



# Degree centrality linear regression model
model_degree <- lm(app_proc_time ~ degree_cen + gender + race + tenure_days, data = final_data)

# Betweenness centrality linear regression model
model_betweenness <- lm(app_proc_time ~ betweenness_cen + gender + race + tenure_days, data = final_data)

# Closeness centrality linear regression model
model_closeness <- lm(app_proc_time ~ closeness_cen + gender + race + tenure_days, data = final_data)

# Display the model summaries
summary(model_degree)
summary(model_betweenness)
summary(model_closeness)
```

Get the summary of the linear regressions!

```{r regression gender1}
model_degree_interaction <- lm(app_proc_time ~ degree_cen * gender + race + tenure_days, data = final_data)
model_betweenness_interaction <- lm(app_proc_time ~ betweenness_cen * gender + race + tenure_days, data = final_data)
model_closeness_interaction <- lm(app_proc_time ~ closeness_cen * gender + race + tenure_days, data = final_data)

summary(model_degree_interaction)
summary(model_betweenness_interaction)
summary(model_closeness_interaction)
```

Interpretations:

On an average looking at the linear regression models:

if the race is white application processing time decreases by the most

if the race is hispanic application processing time increases by the most

if gender is male it takes less time than female

longer the tenure more the time taken

and if a male is processing an application of another male then it makes a significant decrease in time

